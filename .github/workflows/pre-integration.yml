
name: Pre-Integration

on:
  pull_request:
    types:
      - opened
      - synchronize
      - reopened

jobs:
  deploy_integration_resources:
    environment: "azure"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Log in to azure
        shell: pwsh
        run: |
          az login --service-principal `
            -u ${{ secrets.SPN_CLIENT_ID }} `
            -p ${{ secrets.SPN_CLIENT_SECRET }} `
            --tenant ${{ secrets.SPN_TENANT_ID }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false

      - name: Databricks Metastore Terraform
        env:
          ARM_ACCESS_KEY: ${{ secrets.BACKEND_STORAGE_ACCESS_KEY }}
          ARM_CLIENT_ID: ${{ secrets.SPN_CLIENT_ID }}
          ARM_CLIENT_SECRET: ${{ secrets.SPN_CLIENT_SECRET }}
          ARM_TENANT_ID: ${{ secrets.SPN_TENANT_ID }}
          ARM_SUBSCRIPTION_ID: ${{ secrets.SPN_SUBSCRIPTION_ID }}
          TF_VAR_db_account_id: ${{ secrets.DATABRICKS_ACCOUNT_ID }}
        run: |
          terraform -chdir="./.github/terraform/metastore_and_pemanent" init
          terraform -chdir="./.github/terraform/metastore_and_pemanent" apply -auto-approve

      - name: Integration Resources Terraform
        env:
          TF_VAR_db_account_id: ${{ secrets.DATABRICKS_ACCOUNT_ID }}
          TF_VAR_uniqueRunId: ${{ github.run_id }}${{ github.run_attempt }}
        run: |
          terraform -chdir="./.github/terraform/integration_resources" init
          terraform -chdir="./.github/terraform/integration_resources" apply -auto-approve

      - name: Databricks Integration Terraform
        env:
          TF_VAR_db_account_id: ${{ secrets.DATABRICKS_ACCOUNT_ID }}
          TF_VAR_uniqueRunId: ${{ github.run_id }}${{ github.run_attempt }}
        run: |
          terraform -chdir="./.github/terraform/integration_databricks" init
          terraform -chdir="./.github/terraform/integration_databricks" apply -auto-approve

#      - name: Setup Python
#        uses: actions/setup-python@v4
#        with:
#          python-version: "3.11"
#
#      - name: Build Spetlr Library
#        shell: pwsh
#        run: .github/submit/build.ps1
#
#      - name: Setup Databricks CLI
#        shell: bash
#        run: |
#          curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh
#          databricks -v
#
#      - name: Connect to Databricks
#        shell: pwsh
#        run: |
#          .github/submit/connect_DB_api.ps1
#
#
#      - name: Launch integration tests with DBR 14.3
#        shell: pwsh
#        run: |
#          .github/submit/submit_test_job.ps1  `
#            -cluster_env cluster_env_14_3.json `
#            -sparkLibs sparklibs14_3.json


# Don't destroy resources.
#
#      - name: Databricks Integration Terraform Destroy
#        run: terraform -chdir="./.github/terraform/integration_databricks" apply -destroy -auto-approve
#        env:
#          ARM_ACCESS_KEY: ${{ secrets.BACKEND_STORAGE_ACCESS_KEY }}
#          ARM_CLIENT_ID: ${{ secrets.SPN_CLIENT_ID }}
#          ARM_CLIENT_SECRET: ${{ secrets.SPN_CLIENT_SECRET }}
#          ARM_TENANT_ID: ${{ secrets.SPN_TENANT_ID }}
#          ARM_SUBSCRIPTION_ID: ${{ secrets.SPN_SUBSCRIPTION_ID }}
#          TF_VAR_db_account_id: ${{ secrets.DATABRICKS_ACCOUNT_ID }}
#          TF_VAR_uniqueRunId: ${{ github.run_id }}${{ github.run_attempt }}
#
#      - name: Integration Resources Terraform Destroy
#        run: terraform -chdir="./.github/terraform/integration_resources" apply -destroy -auto-approve
#        env:
#          ARM_ACCESS_KEY: ${{ secrets.BACKEND_STORAGE_ACCESS_KEY }}
#          ARM_CLIENT_ID: ${{ secrets.SPN_CLIENT_ID }}
#          ARM_CLIENT_SECRET: ${{ secrets.SPN_CLIENT_SECRET }}
#          ARM_TENANT_ID: ${{ secrets.SPN_TENANT_ID }}
#          ARM_SUBSCRIPTION_ID: ${{ secrets.SPN_SUBSCRIPTION_ID }}
#          TF_VAR_db_account_id: ${{ secrets.DATABRICKS_ACCOUNT_ID }}
#          TF_VAR_uniqueRunId: ${{ github.run_id }}${{ github.run_attempt }}

      - name: Destroy Azure resources
        if: always()
        shell: pwsh
        run: |
          az login --service-principal `
            -u ${{ secrets.SPN_CLIENT_ID }} `
            -p ${{ secrets.SPN_CLIENT_SECRET }} `
            --tenant ${{ secrets.SPN_TENANT_ID }}

          ./.github/deploy/cleanup-integration.ps1

      - name: Azure logout
        if: always()
        shell: pwsh
        run: az logout


# on:
#   pull_request:
#     types:
#       - opened
#       - synchronize
#       - reopened

# jobs:
#   unit_test:
#     runs-on: ubuntu-latest
#     strategy:
#       matrix:
#         python_version:
#           - "3.11"
#     steps:
#       - uses: actions/checkout@v4
#       - name: Setup Python
#         uses: actions/setup-python@v4
#         with:
#           python-version: ${{ matrix.python_version }}
#       - uses: actions/setup-java@v4
#       # this workflow needs java so that it can run a local instance of spark
#         with:
#           java-version: "11"
#           distribution: "temurin"
#       - name: Install the package
#         run: pip install .
#       - name: Install test requirements
#         run: pip install -r requirements_dev.txt
#       - name: Check code formatting
#         run: |
#           black --check .
#           isort --check .
#       - name: Check code linting
#         run: flake8 . --exclude tests
#       - name: Run Tests
#         run: python -m pytest tests/local

#   integration_test:
#     #    needs: unit_test # integration can be run in parallel with unit-tests
#     runs-on: ubuntu-latest
#     environment: azure
#     concurrency: azure-integration
#     steps:
#       - uses: actions/checkout@v4

#       - name: Setup Python
#         uses: actions/setup-python@v4
#         with:
#           python-version: "3.10"

#       - name: Build Spetlr Library
#         shell: pwsh
#         run: .github/submit/build.ps1

#       - name: Log in to azure
#         shell: pwsh
#         run: |
#           az login --service-principal `
#             -u ${{ secrets.SPN_CLIENT_ID }} `
#             -p ${{ secrets.SPN_CLIENT_SECRET }} `
#             --tenant ${{ secrets.SPN_TENANT_ID }} `
#             --output none

#       - name: Setup Databricks CLI
#         shell: bash
#         run: |
#           curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh
#           databricks -v

#       - name: Create deployment
#         shell: pwsh
#         run: |
#           .github/deploy/deploy.ps1 `
#             -pipelineClientId ${{ secrets.SPN_CLIENT_ID }} `
#             -uniqueRunId "${{ github.run_id }}${{ github.run_attempt }}"

#       - name: Launch integration tests with DBR 14.3
#         shell: pwsh
#         run: |
#           .github/submit/submit_test_job.ps1  `
#             -cluster_env cluster_env_14_3.json `
#             -sparkLibs sparklibs14_3.json

#       - name: Wait 2 minutes for reviewing test results
#         shell: pwsh
#         run: Start-Sleep -s 120

#       - name: Delete Deployment
#         if: always() # this step runs even if the pipeline is manually cancelled
#         shell: pwsh
#         run: |
#           az login --service-principal `
#             -u ${{ secrets.SPN_CLIENT_ID }} `
#             -p ${{ secrets.SPN_CLIENT_SECRET }} `
#             --tenant ${{ secrets.SPN_TENANT_ID }} `
#             --output none

#           .github/deploy/destroy.ps1 `
#             -uniqueRunId "${{ github.run_id }}${{ github.run_attempt }}"
